nohup: ignoring input
If for semantic segmentation, please install mmsegmentation first
/home/ping.he/projects/MDE/projects/CAEFD/nets/models/FastViT_LiamEdge.py:957: UserWarning: Overwriting fastvit_t8 in registry with nets.models.FastViT_LiamEdge.fastvit_t8. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  def fastvit_t8(pretrained=False, **kwargs):
/home/ping.he/projects/MDE/projects/CAEFD/nets/models/FastViT_LiamEdge.py:979: UserWarning: Overwriting fastvit_t12 in registry with nets.models.FastViT_LiamEdge.fastvit_t12. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  def fastvit_t12(pretrained=False, **kwargs):
/home/ping.he/projects/MDE/projects/CAEFD/nets/models/FastViT_LiamEdge.py:1001: UserWarning: Overwriting fastvit_s12 in registry with nets.models.FastViT_LiamEdge.fastvit_s12. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  def fastvit_s12(pretrained=False, **kwargs):
/home/ping.he/projects/MDE/projects/CAEFD/nets/models/FastViT_LiamEdge.py:1024: UserWarning: Overwriting fastvit_sa12 in registry with nets.models.FastViT_LiamEdge.fastvit_sa12. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  def fastvit_sa12(pretrained=False, **kwargs):
/home/ping.he/projects/MDE/projects/CAEFD/nets/models/FastViT_LiamEdge.py:1048: UserWarning: Overwriting fastvit_sa24 in registry with nets.models.FastViT_LiamEdge.fastvit_sa24. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  def fastvit_sa24(pretrained=False, **kwargs):
/home/ping.he/projects/MDE/projects/CAEFD/nets/models/FastViT_LiamEdge.py:1072: UserWarning: Overwriting fastvit_sa36 in registry with nets.models.FastViT_LiamEdge.fastvit_sa36. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  def fastvit_sa36(pretrained=False, **kwargs):
/home/ping.he/projects/MDE/projects/CAEFD/nets/models/FastViT_LiamEdge.py:1097: UserWarning: Overwriting fastvit_ma36 in registry with nets.models.FastViT_LiamEdge.fastvit_ma36. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  def fastvit_ma36(pretrained=False, **kwargs):
********** Trainer Initializing **********
2024-06-27 16:39:55 - [34m[1mLOGS[0m - model_name:MobileNetV2Edge
class name: <class 'nets.modules.tf_block_topformer.CrossModalBasicLayerV3M4'>
drop_path:[0.0, 0.03333333507180214, 0.06666666269302368, 0.10000000149011612]
self.alpha_list[0]:Parameter containing:
tensor([0.5000], requires_grad=True)
self.alpha_list[1]:Parameter containing:
tensor([0.5000], requires_grad=True)
self.alpha_list[2]:Parameter containing:
tensor([0.5000], requires_grad=True)
len(self.transformer_blocks):12
2024-06-27 16:39:55 - [34m[1mLOGS[0m - pretrained_path:/home/ping.he/projects/MDE/projects/CAEFD/model/weights/TopFormer-B_512x512_2x8_160k-38.3.pth
2024-06-27 16:39:57 - [34m[1mLOGS[0m - There exists missing keys.
2024-06-27 16:39:57 - [32m[1mINFO[0m - dataset_name: nyu_reduced
2024-06-27 16:39:57 - [32m[1mINFO[0m - model_name: MobileNetV2Edge
2024-06-27 16:39:57 - [32m[1mINFO[0m - Training max epochs: 20
2024-06-27 16:39:57 - [32m[1mINFO[0m - Maximum Depth of Dataset: 10.0
2024-06-27 16:39:57 - [32m[1mINFO[0m - cuda_visible: 0
2024-06-27 16:39:57 - [32m[1mINFO[0m - self.device: cuda:0
2024-06-27 16:39:57 - [32m[1mINFO[0m - Train model: MobileNetV2Edge
2024-06-27 16:39:57 - [32m[1mINFO[0m - self.train_edge: False
2024-06-27 16:39:57 - [32m[1mINFO[0m - self.use_depthnorm: True
2024-06-27 16:39:57 - [32m[1mINFO[0m - train & evaluation resolution: (480, 640)
2024-06-27 16:39:57 - [32m[1mINFO[0m - data_path: /home/ping.he/projects/MDE/dataset/nyu/nyu_data
2024-06-27 16:39:57 - [32m[1mINFO[0m - batch_size: 32
2024-06-27 16:39:57 - [32m[1mINFO[0m - num_workers: 128
2024-06-27 16:39:57 - [32m[1mINFO[0m - Number of parameter: 3.29M
********** Train & Val Dataloader Initializing **********
2024-06-27 16:39:57 - [32m[1mINFO[0m - learning_rate: 0.0001
2024-06-27 16:39:57 - [32m[1mINFO[0m - optimizer: adam
2024-06-27 16:39:57 - [32m[1mINFO[0m - lr_scheduler: step
Depth Loss ------ L1:0.1 ssim:1 gradient:1
2024-06-27 16:39:57 - [32m[1mINFO[0m - checkpoint_path: ./checkpoints/MobileNetV2-TP_ENV4_TMV3M4_LearnableAlpha_OHV4_240627_2
********** Evaluator Initializing **********
2024-06-27 16:39:57 - [32m[1mINFO[0m - self.crop: [20, 460, 24, 616]
2024-06-27 16:39:57 - [32m[1mINFO[0m - self.eval_mode: alhashim
2024-06-27 16:39:57 - [32m[1mINFO[0m - eval_results_path: ./checkpoints/MobileNetV2-TP_ENV4_TMV3M4_LearnableAlpha_OHV4_240627_2/eval_results
2024-06-27 16:39:57 - [32m[1mINFO[0m - test_dataset_path: /home/ping.he/projects/MDE/dataset/nyu/nyu_test
********** Test Dataloader Initializing **********
flag1
flag2
flag3
flag4
self.rgb shape: torch.Size([654, 480, 640, 3])
self.depth shape: torch.Size([654, 480, 640])
flag5
16:39 - Epoch 0
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:3631: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:3679: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. 
  warnings.warn(
Epoch [0][0/1584]	Time 27.737 (27.737)	ETA 12:12:15	LOSS 1.25	pred 6.2148/-4.7907	lr 0.0001	
Epoch [0][200/1584]	Time 0.295 (92.130)	ETA 0:06:48	LOSS 0.20	pred 8.2402/0.3384	lr 0.0001	
Epoch [0][400/1584]	Time 0.298 (156.278)	ETA 0:05:53	LOSS 0.18	pred 10.8094/0.6551	lr 0.0001	
Epoch [0][600/1584]	Time 0.299 (221.710)	ETA 0:04:54	LOSS 0.16	pred 11.9098/0.7957	lr 0.0001	
Epoch [0][800/1584]	Time 0.316 (287.110)	ETA 0:04:08	LOSS 0.15	pred 10.9506/0.8998	lr 0.0001	
Epoch [0][1000/1584]	Time 0.303 (349.882)	ETA 0:02:57	LOSS 0.15	pred 10.3178/0.7325	lr 0.0001	
Epoch [0][1200/1584]	Time 0.314 (411.879)	ETA 0:02:00	LOSS 0.21	pred 10.4859/0.8825	lr 0.0001	
Epoch [0][1400/1584]	Time 0.297 (472.527)	ETA 0:00:54	LOSS 0.13	pred 10.9764/1.0391	lr 0.0001	
2024-06-27 16:48:46 - [34m[1mLOGS[0m - 16:48 - Average Training Loss: 0.0063
16:49 - Average Validation Loss: 0.0047

*
Delta1=0.727
Delta2=0.942
Delta3=0.987
RMSE=0.666
REL=0.178
Lg10=0.074
SqREL=0.140
MAE=0.099
t_GPU=0.055

2024-06-27 16:49:03 - [34m[1mLOGS[0m - Train and validate this epoch took 9.09min
16:49 - Epoch 1
Epoch [1][0/1584]	Time 23.776 (23.776)	ETA 10:27:41	LOSS 0.13	pred 13.0667/1.1274	lr 0.0001	
Epoch [1][200/1584]	Time 0.298 (87.318)	ETA 0:06:52	LOSS 0.14	pred 11.9976/0.8746	lr 0.0001	
Epoch [1][400/1584]	Time 0.318 (150.335)	ETA 0:06:16	LOSS 0.13	pred 12.0742/0.7964	lr 0.0001	
Epoch [1][600/1584]	Time 0.305 (214.616)	ETA 0:05:00	LOSS 0.12	pred 12.6560/0.8872	lr 0.0001	
Epoch [1][800/1584]	Time 0.298 (275.916)	ETA 0:03:53	LOSS 0.14	pred 13.3547/0.8381	lr 0.0001	
Epoch [1][1000/1584]	Time 0.297 (337.615)	ETA 0:02:53	LOSS 0.12	pred 14.2171/0.8401	lr 0.0001	
Epoch [1][1200/1584]	Time 0.325 (398.916)	ETA 0:02:04	LOSS 0.11	pred 11.6842/0.8218	lr 0.0001	
Epoch [1][1400/1584]	Time 0.298 (460.196)	ETA 0:00:54	LOSS 0.11	pred 11.4133/0.8563	lr 0.0001	
2024-06-27 16:57:40 - [34m[1mLOGS[0m - 16:57 - Average Training Loss: 0.0040
16:58 - Average Validation Loss: 0.0045

*
Delta1=0.750
Delta2=0.949
Delta3=0.988
RMSE=0.633
REL=0.174
Lg10=0.070
SqREL=0.135
MAE=0.095
t_GPU=0.055

2024-06-27 16:58:02 - [34m[1mLOGS[0m - Train and validate this epoch took 8.99min
16:58 - Epoch 2
Epoch [2][0/1584]	Time 22.566 (22.566)	ETA 9:55:43	LOSS 0.12	pred 12.0518/0.9531	lr 0.0001	
Epoch [2][200/1584]	Time 0.297 (84.395)	ETA 0:06:50	LOSS 0.14	pred 12.3600/0.7208	lr 0.0001	
Epoch [2][400/1584]	Time 0.505 (147.651)	ETA 0:09:57	LOSS 0.13	pred 13.3062/1.0996	lr 0.0001	
Epoch [2][600/1584]	Time 0.301 (212.045)	ETA 0:04:55	LOSS 0.12	pred 12.5915/1.1247	lr 0.0001	
Epoch [2][800/1584]	Time 0.297 (273.170)	ETA 0:03:53	LOSS 0.11	pred 13.4740/0.5735	lr 0.0001	
Epoch [2][1000/1584]	Time 0.314 (334.063)	ETA 0:03:03	LOSS 0.13	pred 13.9103/0.9997	lr 0.0001	
Epoch [2][1200/1584]	Time 0.322 (395.040)	ETA 0:02:03	LOSS 0.11	pred 11.9607/0.8965	lr 0.0001	
Epoch [2][1400/1584]	Time 0.298 (455.889)	ETA 0:00:54	LOSS 0.10	pred 11.3964/1.1140	lr 0.0001	
2024-06-27 17:06:35 - [34m[1mLOGS[0m - 17:06 - Average Training Loss: 0.0037
17:07 - Average Validation Loss: 0.0043

*
Delta1=0.770
Delta2=0.956
Delta3=0.991
RMSE=0.617
REL=0.159
Lg10=0.067
SqREL=0.118
MAE=0.090
t_GPU=0.063

2024-06-27 17:07:00 - [34m[1mLOGS[0m - Train and validate this epoch took 8.96min
17:07 - Epoch 3
Epoch [3][0/1584]	Time 23.478 (23.478)	ETA 10:19:48	LOSS 0.11	pred 12.5275/0.5127	lr 0.0001	
Epoch [3][200/1584]	Time 0.301 (88.023)	ETA 0:06:56	LOSS 0.11	pred 11.7418/1.0092	lr 0.0001	
Epoch [3][400/1584]	Time 0.298 (153.609)	ETA 0:05:52	LOSS 0.11	pred 12.6959/0.9670	lr 0.0001	
Epoch [3][600/1584]	Time 0.301 (214.723)	ETA 0:04:56	LOSS 0.11	pred 13.3515/1.0741	lr 0.0001	
Epoch [3][800/1584]	Time 0.302 (276.584)	ETA 0:03:56	LOSS 0.11	pred 13.9467/1.2520	lr 0.0001	
Epoch [3][1000/1584]	Time 0.298 (337.844)	ETA 0:02:53	LOSS 0.09	pred 12.2545/0.9889	lr 0.0001	
Epoch [3][1200/1584]	Time 0.315 (399.494)	ETA 0:02:01	LOSS 0.10	pred 13.5463/0.7136	lr 0.0001	
Epoch [3][1400/1584]	Time 0.301 (460.699)	ETA 0:00:55	LOSS 0.10	pred 13.9063/1.0573	lr 0.0001	
2024-06-27 17:15:37 - [34m[1mLOGS[0m - 17:15 - Average Training Loss: 0.0034
17:16 - Average Validation Loss: 0.0042

*
Delta1=0.782
Delta2=0.957
Delta3=0.991
RMSE=0.607
REL=0.155
Lg10=0.065
SqREL=0.114
MAE=0.089
t_GPU=0.062

2024-06-27 17:16:04 - [34m[1mLOGS[0m - Train and validate this epoch took 9.07min
17:16 - Epoch 4
Epoch [4][0/1584]	Time 29.594 (29.594)	ETA 13:01:17	LOSS 0.10	pred 14.4010/1.0447	lr 0.0001	
Epoch [4][200/1584]	Time 0.297 (95.124)	ETA 0:06:50	LOSS 0.11	pred 13.7147/1.1047	lr 0.0001	
Epoch [4][400/1584]	Time 0.301 (160.148)	ETA 0:05:56	LOSS 0.12	pred 13.2901/1.0769	lr 0.0001	
Epoch [4][600/1584]	Time 0.302 (221.121)	ETA 0:04:57	LOSS 0.11	pred 12.0986/1.0886	lr 0.0001	
Epoch [4][800/1584]	Time 0.303 (282.419)	ETA 0:03:57	LOSS 0.11	pred 13.3981/0.9048	lr 0.0001	
Epoch [4][1000/1584]	Time 0.303 (343.746)	ETA 0:02:56	LOSS 0.10	pred 13.4845/1.0404	lr 0.0001	
Epoch [4][1200/1584]	Time 0.304 (404.635)	ETA 0:01:56	LOSS 0.12	pred 13.7562/0.8971	lr 0.0001	
Epoch [4][1400/1584]	Time 0.298 (466.029)	ETA 0:00:54	LOSS 0.10	pred 14.4138/1.0132	lr 0.0001	
2024-06-27 17:24:47 - [34m[1mLOGS[0m - 17:24 - Average Training Loss: 0.0033
17:25 - Average Validation Loss: 0.0041

*
Delta1=0.788
Delta2=0.961
Delta3=0.992
RMSE=0.602
REL=0.148
Lg10=0.064
SqREL=0.107
MAE=0.087
t_GPU=0.063

2024-06-27 17:25:13 - [34m[1mLOGS[0m - Train and validate this epoch took 9.16min
17:25 - Epoch 5
Epoch [5][0/1584]	Time 22.558 (22.558)	ETA 9:55:31	LOSS 0.10	pred 13.0702/0.8483	lr 0.0001	
Epoch [5][200/1584]	Time 0.312 (89.946)	ETA 0:07:11	LOSS 0.10	pred 13.2706/1.0704	lr 0.0001	
Epoch [5][400/1584]	Time 0.325 (151.126)	ETA 0:06:25	LOSS 0.10	pred 12.2589/1.2702	lr 0.0001	
Epoch [5][600/1584]	Time 0.297 (212.647)	ETA 0:04:52	LOSS 0.11	pred 15.2647/0.9410	lr 0.0001	
Epoch [5][800/1584]	Time 0.297 (274.347)	ETA 0:03:53	LOSS 0.09	pred 12.9081/1.1073	lr 0.0001	
Epoch [5][1000/1584]	Time 0.316 (335.463)	ETA 0:03:04	LOSS 0.09	pred 13.5549/1.0508	lr 0.0001	
Epoch [5][1200/1584]	Time 0.302 (397.275)	ETA 0:01:55	LOSS 0.10	pred 15.8920/1.0307	lr 0.0001	
Epoch [5][1400/1584]	Time 0.301 (458.291)	ETA 0:00:55	LOSS 0.10	pred 13.4755/1.0732	lr 0.0001	
2024-06-27 17:33:49 - [34m[1mLOGS[0m - 17:33 - Average Training Loss: 0.0031
17:34 - Average Validation Loss: 0.0041

*
Delta1=0.791
Delta2=0.959
Delta3=0.992
RMSE=0.593
REL=0.152
Lg10=0.064
SqREL=0.108
MAE=0.087
t_GPU=0.059

2024-06-27 17:34:10 - [34m[1mLOGS[0m - Train and validate this epoch took 8.96min
17:34 - Epoch 6
Epoch [6][0/1584]	Time 26.881 (26.881)	ETA 11:49:38	LOSS 0.10	pred 12.9414/1.0560	lr 0.0001	
Epoch [6][200/1584]	Time 0.319 (94.090)	ETA 0:07:21	LOSS 0.08	pred 13.9245/0.9649	lr 0.0001	
Epoch [6][400/1584]	Time 0.315 (155.611)	ETA 0:06:12	LOSS 0.10	pred 13.7657/1.1071	lr 0.0001	
Epoch [6][600/1584]	Time 0.310 (216.895)	ETA 0:05:05	LOSS 0.10	pred 14.3542/0.8178	lr 0.0001	
Epoch [6][800/1584]	Time 0.302 (277.852)	ETA 0:03:56	LOSS 0.10	pred 13.6464/0.8379	lr 0.0001	
Epoch [6][1000/1584]	Time 0.300 (339.092)	ETA 0:02:55	LOSS 0.10	pred 14.0597/1.0529	lr 0.0001	
Epoch [6][1200/1584]	Time 0.310 (400.095)	ETA 0:01:58	LOSS 0.10	pred 12.9821/1.0436	lr 0.0001	
Epoch [6][1400/1584]	Time 0.298 (460.583)	ETA 0:00:54	LOSS 0.10	pred 13.4327/1.0704	lr 0.0001	
2024-06-27 17:42:48 - [34m[1mLOGS[0m - 17:42 - Average Training Loss: 0.0030
17:43 - Average Validation Loss: 0.0041

*
Delta1=0.798
Delta2=0.963
Delta3=0.992
RMSE=0.588
REL=0.147
Lg10=0.063
SqREL=0.104
MAE=0.085
t_GPU=0.052

2024-06-27 17:43:03 - [34m[1mLOGS[0m - Train and validate this epoch took 8.87min
17:43 - Epoch 7
Epoch [7][0/1584]	Time 20.391 (20.391)	ETA 8:58:19	LOSS 0.10	pred 12.6817/1.0612	lr 0.0001	
Epoch [7][200/1584]	Time 0.299 (85.060)	ETA 0:06:53	LOSS 0.10	pred 12.9031/1.0548	lr 0.0001	
Epoch [7][400/1584]	Time 0.295 (145.509)	ETA 0:05:49	LOSS 0.10	pred 13.4006/0.9690	lr 0.0001	
Epoch [7][600/1584]	Time 0.309 (206.561)	ETA 0:05:04	LOSS 0.10	pred 14.1025/1.0501	lr 0.0001	
Epoch [7][800/1584]	Time 0.316 (267.272)	ETA 0:04:07	LOSS 0.10	pred 13.1745/1.0405	lr 0.0001	
Epoch [7][1000/1584]	Time 0.298 (328.479)	ETA 0:02:54	LOSS 0.08	pred 12.6047/0.9781	lr 0.0001	
Epoch [7][1200/1584]	Time 0.298 (389.191)	ETA 0:01:54	LOSS 0.09	pred 14.2174/1.1149	lr 0.0001	
Epoch [7][1400/1584]	Time 0.300 (449.800)	ETA 0:00:55	LOSS 0.09	pred 13.4411/1.1271	lr 0.0001	
2024-06-27 17:51:29 - [34m[1mLOGS[0m - 17:51 - Average Training Loss: 0.0030
17:51 - Average Validation Loss: 0.0040

*
Delta1=0.803
Delta2=0.963
Delta3=0.991
RMSE=0.584
REL=0.146
Lg10=0.062
SqREL=0.105
MAE=0.085
t_GPU=0.059

2024-06-27 17:51:48 - [34m[1mLOGS[0m - Train and validate this epoch took 8.75min
17:51 - Epoch 8
Epoch [8][0/1584]	Time 25.976 (25.976)	ETA 11:25:46	LOSS 0.10	pred 11.5875/1.0321	lr 0.0001	
Epoch [8][200/1584]	Time 0.303 (90.059)	ETA 0:06:58	LOSS 0.10	pred 15.2978/1.0357	lr 0.0001	
Epoch [8][400/1584]	Time 0.308 (151.043)	ETA 0:06:04	LOSS 0.09	pred 12.7337/1.0053	lr 0.0001	
Epoch [8][600/1584]	Time 0.304 (211.852)	ETA 0:04:59	LOSS 0.08	pred 12.0750/1.0175	lr 0.0001	
Epoch [8][800/1584]	Time 0.310 (272.877)	ETA 0:04:02	LOSS 0.09	pred 13.4401/0.9006	lr 0.0001	
Epoch [8][1000/1584]	Time 0.314 (333.742)	ETA 0:03:03	LOSS 0.09	pred 13.2555/0.9525	lr 0.0001	
Epoch [8][1200/1584]	Time 0.297 (394.796)	ETA 0:01:54	LOSS 0.09	pred 13.9116/1.0466	lr 0.0001	
Epoch [8][1400/1584]	Time 0.299 (455.592)	ETA 0:00:54	LOSS 0.13	pred 14.0994/1.1089	lr 0.0001	
2024-06-27 18:00:20 - [34m[1mLOGS[0m - 18:00 - Average Training Loss: 0.0029
18:00 - Average Validation Loss: 0.0040

*
Delta1=0.807
Delta2=0.963
Delta3=0.992
RMSE=0.579
REL=0.143
Lg10=0.061
SqREL=0.101
MAE=0.084
t_GPU=0.051

2024-06-27 18:00:34 - [34m[1mLOGS[0m - Train and validate this epoch took 8.76min
18:00 - Epoch 9
Epoch [9][0/1584]	Time 22.810 (22.810)	ETA 10:02:10	LOSS 0.09	pred 14.5601/0.9490	lr 0.0001	
Epoch [9][200/1584]	Time 0.310 (89.817)	ETA 0:07:09	LOSS 0.10	pred 13.3825/1.1444	lr 0.0001	
Epoch [9][400/1584]	Time 0.323 (151.612)	ETA 0:06:22	LOSS 0.10	pred 12.2838/0.9081	lr 0.0001	
Epoch [9][600/1584]	Time 0.295 (212.463)	ETA 0:04:50	LOSS 0.10	pred 13.7035/0.7787	lr 0.0001	
Epoch [9][800/1584]	Time 0.298 (273.198)	ETA 0:03:53	LOSS 0.09	pred 10.9536/0.8946	lr 0.0001	
Epoch [9][1000/1584]	Time 0.296 (333.653)	ETA 0:02:52	LOSS 0.10	pred 15.7919/0.9384	lr 0.0001	
Epoch [9][1200/1584]	Time 0.313 (394.891)	ETA 0:02:00	LOSS 0.09	pred 13.3661/0.9945	lr 0.0001	
Epoch [9][1400/1584]	Time 0.299 (455.240)	ETA 0:00:54	LOSS 0.10	pred 14.3504/1.1054	lr 0.0001	
2024-06-27 18:09:06 - [34m[1mLOGS[0m - 18:09 - Average Training Loss: 0.0028
18:09 - Average Validation Loss: 0.0040

*
Delta1=0.808
Delta2=0.964
Delta3=0.992
RMSE=0.576
REL=0.142
Lg10=0.061
SqREL=0.099
MAE=0.084
t_GPU=0.057

2024-06-27 18:09:22 - [34m[1mLOGS[0m - Train and validate this epoch took 8.81min
18:09 - Epoch 10
Epoch [10][0/1584]	Time 18.658 (18.658)	ETA 8:12:33	LOSS 0.09	pred 15.0533/0.8592	lr 0.0001	
Epoch [10][200/1584]	Time 0.298 (87.076)	ETA 0:06:52	LOSS 0.08	pred 13.3769/0.9871	lr 0.0001	
Epoch [10][400/1584]	Time 0.299 (147.682)	ETA 0:05:53	LOSS 0.09	pred 13.0787/1.0268	lr 0.0001	
Epoch [10][600/1584]	Time 0.299 (208.349)	ETA 0:04:53	LOSS 0.09	pred 13.1638/0.9722	lr 0.0001	
Epoch [10][800/1584]	Time 0.313 (269.829)	ETA 0:04:05	LOSS 0.09	pred 13.4625/0.9493	lr 0.0001	
Epoch [10][1000/1584]	Time 0.305 (331.433)	ETA 0:02:57	LOSS 0.09	pred 12.8792/0.9570	lr 0.0001	
Epoch [10][1200/1584]	Time 0.298 (392.483)	ETA 0:01:54	LOSS 0.09	pred 15.6642/1.0503	lr 0.0001	
Epoch [10][1400/1584]	Time 0.297 (452.902)	ETA 0:00:54	LOSS 0.10	pred 14.9767/0.8529	lr 0.0001	
2024-06-27 18:17:52 - [34m[1mLOGS[0m - 18:17 - Average Training Loss: 0.0028
18:18 - Average Validation Loss: 0.0039

*
Delta1=0.806
Delta2=0.966
Delta3=0.993
RMSE=0.575
REL=0.142
Lg10=0.061
SqREL=0.098
MAE=0.083
t_GPU=0.056

18:18 - Model saved
2024-06-27 18:18:12 - [34m[1mLOGS[0m - Train and validate this epoch took 8.82min
18:18 - Epoch 11
Epoch [11][0/1584]	Time 28.484 (28.484)	ETA 12:31:58	LOSS 0.09	pred 13.2612/0.8144	lr 0.0001	
Epoch [11][200/1584]	Time 0.302 (90.784)	ETA 0:06:58	LOSS 0.08	pred 12.2798/1.0049	lr 0.0001	
Epoch [11][400/1584]	Time 0.310 (153.239)	ETA 0:06:06	LOSS 0.10	pred 13.1707/1.0210	lr 0.0001	
Epoch [11][600/1584]	Time 0.326 (215.321)	ETA 0:05:21	LOSS 0.09	pred 13.7576/1.1557	lr 0.0001	
Epoch [11][800/1584]	Time 0.327 (276.513)	ETA 0:04:16	LOSS 0.10	pred 13.6777/0.9289	lr 0.0001	
Epoch [11][1000/1584]	Time 0.298 (337.925)	ETA 0:02:53	LOSS 0.09	pred 14.2392/1.0988	lr 0.0001	
Epoch [11][1200/1584]	Time 0.301 (399.589)	ETA 0:01:55	LOSS 0.09	pred 14.7310/0.7333	lr 0.0001	
Epoch [11][1400/1584]	Time 0.302 (460.624)	ETA 0:00:55	LOSS 0.09	pred 13.0085/0.8679	lr 0.0001	
2024-06-27 18:26:50 - [34m[1mLOGS[0m - 18:26 - Average Training Loss: 0.0027
18:27 - Average Validation Loss: 0.0039

*
Delta1=0.814
Delta2=0.966
Delta3=0.992
RMSE=0.566
REL=0.141
Lg10=0.060
SqREL=0.097
MAE=0.082
t_GPU=0.058

18:27 - Model saved
2024-06-27 18:27:11 - [34m[1mLOGS[0m - Train and validate this epoch took 8.99min
18:27 - Epoch 12
Epoch [12][0/1584]	Time 24.758 (24.758)	ETA 10:53:36	LOSS 0.10	pred 13.0541/1.0549	lr 0.0001	
Epoch [12][200/1584]	Time 0.324 (86.289)	ETA 0:07:28	LOSS 0.10	pred 13.5986/1.2645	lr 0.0001	
Epoch [12][400/1584]	Time 0.301 (146.956)	ETA 0:05:56	LOSS 0.08	pred 14.4276/0.8724	lr 0.0001	
Epoch [12][600/1584]	Time 0.298 (208.156)	ETA 0:04:53	LOSS 0.08	pred 14.0810/0.9502	lr 0.0001	
Epoch [12][800/1584]	Time 0.302 (269.409)	ETA 0:03:57	LOSS 0.10	pred 14.2392/1.0798	lr 0.0001	
Epoch [12][1000/1584]	Time 0.317 (330.469)	ETA 0:03:04	LOSS 0.08	pred 15.3427/1.0570	lr 0.0001	
Epoch [12][1200/1584]	Time 0.318 (392.412)	ETA 0:02:02	LOSS 0.09	pred 13.0019/0.9956	lr 0.0001	
Epoch [12][1400/1584]	Time 0.302 (453.372)	ETA 0:00:55	LOSS 0.07	pred 13.6354/1.0594	lr 0.0001	
2024-06-27 18:35:42 - [34m[1mLOGS[0m - 18:35 - Average Training Loss: 0.0027
18:36 - Average Validation Loss: 0.0039

*
Delta1=0.812
Delta2=0.965
Delta3=0.993
RMSE=0.565
REL=0.142
Lg10=0.060
SqREL=0.097
MAE=0.082
t_GPU=0.066

18:36 - Model saved
2024-06-27 18:36:11 - [34m[1mLOGS[0m - Train and validate this epoch took 9.00min
18:36 - Epoch 13
Epoch [13][0/1584]	Time 31.975 (31.975)	ETA 14:04:09	LOSS 0.08	pred 13.5928/1.0368	lr 0.0001	
Epoch [13][200/1584]	Time 0.300 (94.121)	ETA 0:06:55	LOSS 0.08	pred 14.1106/1.0036	lr 0.0001	
Epoch [13][400/1584]	Time 0.301 (155.274)	ETA 0:05:56	LOSS 0.09	pred 14.5627/0.8641	lr 0.0001	
Epoch [13][600/1584]	Time 0.301 (217.175)	ETA 0:04:56	LOSS 0.08	pred 12.5622/0.9682	lr 0.0001	
Epoch [13][800/1584]	Time 0.309 (278.748)	ETA 0:04:02	LOSS 0.09	pred 13.6760/1.0665	lr 0.0001	
Epoch [13][1000/1584]	Time 0.303 (340.303)	ETA 0:02:57	LOSS 0.08	pred 14.4354/1.0504	lr 0.0001	
Epoch [13][1200/1584]	Time 0.301 (401.703)	ETA 0:01:55	LOSS 0.10	pred 14.5042/0.8082	lr 0.0001	
Epoch [13][1400/1584]	Time 0.297 (462.555)	ETA 0:00:54	LOSS 0.09	pred 13.7516/0.9639	lr 0.0001	
2024-06-27 18:44:51 - [34m[1mLOGS[0m - 18:44 - Average Training Loss: 0.0027
18:45 - Average Validation Loss: 0.0039

*
Delta1=0.809
Delta2=0.966
Delta3=0.993
RMSE=0.566
REL=0.141
Lg10=0.060
SqREL=0.098
MAE=0.082
t_GPU=0.055

18:45 - Model saved
2024-06-27 18:45:10 - [34m[1mLOGS[0m - Train and validate this epoch took 8.98min
18:45 - Epoch 14
Epoch [14][0/1584]	Time 19.544 (19.544)	ETA 8:35:57	LOSS 0.07	pred 11.6841/0.9566	lr 0.0001	
Epoch [14][200/1584]	Time 0.301 (84.324)	ETA 0:06:56	LOSS 0.09	pred 14.8980/1.0744	lr 0.0001	
Epoch [14][400/1584]	Time 0.298 (145.283)	ETA 0:05:53	LOSS 0.10	pred 14.2229/0.8748	lr 0.0001	
Epoch [14][600/1584]	Time 0.309 (206.814)	ETA 0:05:04	LOSS 0.09	pred 15.5618/0.9603	lr 0.0001	
Epoch [14][800/1584]	Time 0.314 (268.403)	ETA 0:04:05	LOSS 0.08	pred 14.2837/1.0283	lr 0.0001	
Epoch [14][1000/1584]	Time 0.311 (329.538)	ETA 0:03:01	LOSS 0.08	pred 14.5757/1.0162	lr 0.0001	
Epoch [14][1200/1584]	Time 0.297 (390.720)	ETA 0:01:53	LOSS 0.09	pred 13.8885/0.8611	lr 0.0001	
Epoch [14][1400/1584]	Time 0.302 (451.681)	ETA 0:00:55	LOSS 0.07	pred 13.7888/1.0253	lr 0.0001	
2024-06-27 18:53:39 - [34m[1mLOGS[0m - 18:53 - Average Training Loss: 0.0026
18:54 - Average Validation Loss: 0.0039

*
Delta1=0.809
Delta2=0.964
Delta3=0.992
RMSE=0.572
REL=0.142
Lg10=0.060
SqREL=0.099
MAE=0.083
t_GPU=0.062

18:54 - Model saved
2024-06-27 18:54:07 - [34m[1mLOGS[0m - Train and validate this epoch took 8.96min
18:54 - Epoch 15
Epoch [15][0/1584]	Time 20.386 (20.386)	ETA 8:58:11	LOSS 0.08	pred 12.7896/0.8868	lr 1e-05	
Epoch [15][200/1584]	Time 0.301 (84.655)	ETA 0:06:56	LOSS 0.08	pred 12.3594/1.0070	lr 1e-05	
Epoch [15][400/1584]	Time 0.301 (145.776)	ETA 0:05:56	LOSS 0.09	pred 15.1799/1.0316	lr 1e-05	
Epoch [15][600/1584]	Time 0.301 (206.944)	ETA 0:04:56	LOSS 0.06	pred 13.4081/1.0101	lr 1e-05	
Epoch [15][800/1584]	Time 0.314 (267.968)	ETA 0:04:05	LOSS 0.08	pred 13.2750/0.9862	lr 1e-05	
Epoch [15][1000/1584]	Time 0.304 (329.194)	ETA 0:02:57	LOSS 0.08	pred 13.6843/0.9979	lr 1e-05	
Epoch [15][1200/1584]	Time 0.299 (390.760)	ETA 0:01:54	LOSS 0.09	pred 13.9307/0.8698	lr 1e-05	
Epoch [15][1400/1584]	Time 0.301 (451.522)	ETA 0:00:55	LOSS 0.08	pred 12.9301/0.9770	lr 1e-05	
2024-06-27 19:02:36 - [34m[1mLOGS[0m - 19:02 - Average Training Loss: 0.0025
19:03 - Average Validation Loss: 0.0039

*
Delta1=0.814
Delta2=0.966
Delta3=0.992
RMSE=0.569
REL=0.138
Lg10=0.060
SqREL=0.095
MAE=0.082
t_GPU=0.054

19:03 - Model saved
2024-06-27 19:03:03 - [34m[1mLOGS[0m - Train and validate this epoch took 8.94min
19:03 - Epoch 16
Epoch [16][0/1584]	Time 22.409 (22.409)	ETA 9:51:35	LOSS 0.08	pred 14.7416/1.0070	lr 1e-05	
Epoch [16][200/1584]	Time 0.301 (85.508)	ETA 0:06:56	LOSS 0.08	pred 12.9812/1.0889	lr 1e-05	
Epoch [16][400/1584]	Time 0.315 (146.779)	ETA 0:06:13	LOSS 0.07	pred 13.3729/0.9792	lr 1e-05	
Epoch [16][600/1584]	Time 0.317 (208.074)	ETA 0:05:12	LOSS 0.10	pred 14.1027/0.9871	lr 1e-05	
Epoch [16][800/1584]	Time 0.302 (269.507)	ETA 0:03:56	LOSS 0.07	pred 13.4029/1.0092	lr 1e-05	
Epoch [16][1000/1584]	Time 0.297 (330.816)	ETA 0:02:53	LOSS 0.07	pred 15.0081/1.0226	lr 1e-05	
Epoch [16][1200/1584]	Time 0.319 (392.166)	ETA 0:02:02	LOSS 0.08	pred 13.4415/0.9824	lr 1e-05	
Epoch [16][1400/1584]	Time 0.297 (453.267)	ETA 0:00:54	LOSS 0.07	pred 13.7903/0.9172	lr 1e-05	
2024-06-27 19:11:34 - [34m[1mLOGS[0m - 19:11 - Average Training Loss: 0.0025
19:11 - Average Validation Loss: 0.0039

*
Delta1=0.813
Delta2=0.965
Delta3=0.992
RMSE=0.568
REL=0.139
Lg10=0.060
SqREL=0.096
MAE=0.082
t_GPU=0.055

19:11 - Model saved
2024-06-27 19:11:57 - [34m[1mLOGS[0m - Train and validate this epoch took 8.89min
19:11 - Epoch 17
Epoch [17][0/1584]	Time 24.163 (24.163)	ETA 10:37:54	LOSS 0.08	pred 13.4265/1.0304	lr 1e-05	
Epoch [17][200/1584]	Time 0.302 (87.037)	ETA 0:06:57	LOSS 0.08	pred 14.6278/1.0862	lr 1e-05	
Epoch [17][400/1584]	Time 0.322 (148.817)	ETA 0:06:21	LOSS 0.08	pred 13.5534/0.9728	lr 1e-05	
Epoch [17][600/1584]	Time 0.297 (210.611)	ETA 0:04:52	LOSS 0.08	pred 13.6819/0.9534	lr 1e-05	
Epoch [17][800/1584]	Time 0.305 (271.739)	ETA 0:03:59	LOSS 0.07	pred 11.8905/0.9860	lr 1e-05	
Epoch [17][1000/1584]	Time 0.301 (332.776)	ETA 0:02:55	LOSS 0.09	pred 13.8411/0.9857	lr 1e-05	
Epoch [17][1200/1584]	Time 0.314 (394.092)	ETA 0:02:00	LOSS 0.07	pred 13.4212/1.1335	lr 1e-05	
Epoch [17][1400/1584]	Time 0.301 (455.430)	ETA 0:00:55	LOSS 0.08	pred 12.8801/0.9411	lr 1e-05	
2024-06-27 19:20:29 - [34m[1mLOGS[0m - 19:20 - Average Training Loss: 0.0025
19:20 - Average Validation Loss: 0.0039

*
Delta1=0.813
Delta2=0.966
Delta3=0.992
RMSE=0.567
REL=0.138
Lg10=0.060
SqREL=0.095
MAE=0.082
t_GPU=0.056

19:20 - Model saved
2024-06-27 19:20:55 - [34m[1mLOGS[0m - Train and validate this epoch took 8.97min
19:20 - Epoch 18
Epoch [18][0/1584]	Time 22.764 (22.764)	ETA 10:00:58	LOSS 0.08	pred 14.2557/0.8521	lr 1e-05	
Epoch [18][200/1584]	Time 0.313 (89.031)	ETA 0:07:13	LOSS 0.07	pred 14.4570/0.9433	lr 1e-05	
Epoch [18][400/1584]	Time 0.302 (150.342)	ETA 0:05:57	LOSS 0.09	pred 14.9497/0.9684	lr 1e-05	
Epoch [18][600/1584]	Time 0.298 (212.309)	ETA 0:04:53	LOSS 0.07	pred 13.2992/1.0760	lr 1e-05	
Epoch [18][800/1584]	Time 0.303 (273.774)	ETA 0:03:57	LOSS 0.08	pred 13.6963/0.9937	lr 1e-05	
Epoch [18][1000/1584]	Time 0.315 (335.160)	ETA 0:03:04	LOSS 0.08	pred 12.2722/0.9901	lr 1e-05	
Epoch [18][1200/1584]	Time 0.316 (396.760)	ETA 0:02:01	LOSS 0.08	pred 14.0636/1.1155	lr 1e-05	
Epoch [18][1400/1584]	Time 0.302 (457.842)	ETA 0:00:55	LOSS 0.08	pred 14.0408/1.0428	lr 1e-05	
2024-06-27 19:29:30 - [34m[1mLOGS[0m - 19:29 - Average Training Loss: 0.0025
19:29 - Average Validation Loss: 0.0039

*
Delta1=0.814
Delta2=0.966
Delta3=0.992
RMSE=0.567
REL=0.139
Lg10=0.059
SqREL=0.096
MAE=0.082
t_GPU=0.061

19:29 - Model saved
2024-06-27 19:29:58 - [34m[1mLOGS[0m - Train and validate this epoch took 9.06min
19:29 - Epoch 19
Epoch [19][0/1584]	Time 26.513 (26.513)	ETA 11:39:55	LOSS 0.08	pred 14.9708/0.9392	lr 1e-05	
Epoch [19][200/1584]	Time 0.301 (88.868)	ETA 0:06:56	LOSS 0.07	pred 13.2369/1.0686	lr 1e-05	
Epoch [19][400/1584]	Time 0.297 (149.555)	ETA 0:05:51	LOSS 0.09	pred 13.7355/0.9552	lr 1e-05	
Epoch [19][600/1584]	Time 0.298 (210.141)	ETA 0:04:52	LOSS 0.07	pred 11.9178/1.0891	lr 1e-05	
Epoch [19][800/1584]	Time 0.305 (270.880)	ETA 0:03:59	LOSS 0.08	pred 14.5970/1.1733	lr 1e-05	
Epoch [19][1000/1584]	Time 0.298 (331.532)	ETA 0:02:54	LOSS 0.09	pred 13.4409/0.8938	lr 1e-05	
Epoch [19][1200/1584]	Time 0.320 (392.052)	ETA 0:02:02	LOSS 0.10	pred 13.4569/1.1328	lr 1e-05	
Epoch [19][1400/1584]	Time 0.301 (452.228)	ETA 0:00:55	LOSS 0.08	pred 15.0235/0.9555	lr 1e-05	
2024-06-27 19:38:27 - [34m[1mLOGS[0m - 19:38 - Average Training Loss: 0.0025
19:38 - Average Validation Loss: 0.0039

*
Delta1=0.816
Delta2=0.966
Delta3=0.992
RMSE=0.561
REL=0.140
Lg10=0.059
SqREL=0.096
MAE=0.082
t_GPU=0.058

19:38 - Model saved
2024-06-27 19:38:48 - [34m[1mLOGS[0m - Train and validate this epoch took 8.83min
ckpt_19: ([1, 5, 1, 1, 5, 5], 3, 3.0)
ckpt_18: ([5, 4, 2, 2, 3, 6], 0, 3.6666666666666665)
ckpt_17: ([6, 2, 4, 5, 4, 4], 0, 4.166666666666667)
ckpt_15: ([8, 1, 3, 4, 1, 9], 2, 4.333333333333333)
ckpt_11: ([4, 6, 6, 3, 2, 8], 0, 4.833333333333333)
ckpt_13: ([3, 7, 8, 9, 6, 1], 1, 5.666666666666667)
ckpt_12: ([2, 8, 7, 7, 9, 3], 0, 6.0)
ckpt_16: ([7, 3, 5, 6, 8, 7], 0, 6.0)
ckpt_10: ([10, 9, 11, 12, 7, 2], 0, 8.5)
ckpt_14: ([9, 10, 9, 8, 10, 12], 0, 9.666666666666666)
ckpt_9: ([11, 11, 10, 10, 11, 10], 0, 10.5)
ckpt_8: ([12, 12, 12, 11, 13, 11], 0, 11.833333333333334)
ckpt_7: ([13, 13, 13, 13, 12, 16], 0, 13.333333333333334)
ckpt_6: ([14, 14, 14, 14, 14, 13], 0, 13.833333333333334)
ckpt_5: ([15, 16, 15, 15, 16, 14], 0, 15.166666666666666)
ckpt_4: ([16, 15, 16, 16, 15, 15], 0, 15.5)
ckpt_3: ([17, 17, 17, 17, 17, 18], 0, 17.166666666666668)
ckpt_2: ([18, 18, 18, 18, 18, 17], 0, 17.833333333333332)
ckpt_1: ([19, 19, 19, 19, 19, 19], 0, 19.0)
ckpt_0: ([20, 20, 20, 20, 20, 20], 0, 20.0)
Start evaluating these chosen best checkpoints...
2024-06-27 19:38:48 - [34m[1mLOGS[0m - model_name:MobileNetV2Edge
class name: <class 'nets.modules.tf_block_topformer.CrossModalBasicLayerV3M4'>
drop_path:[0.0, 0.03333333507180214, 0.06666666269302368, 0.10000000149011612]
self.alpha_list[0]:Parameter containing:
tensor([0.5000], requires_grad=True)
self.alpha_list[1]:Parameter containing:
tensor([0.5000], requires_grad=True)
self.alpha_list[2]:Parameter containing:
tensor([0.5000], requires_grad=True)
len(self.transformer_blocks):12
2024-06-27 19:38:48 - [34m[1mLOGS[0m - best_model_path:./checkpoints/MobileNetV2-TP_ENV4_TMV3M4_LearnableAlpha_OHV4_240627_2/checkpoint_19.pth
2024-06-27 19:38:48 - [34m[1mLOGS[0m - The best model weights loaded w/o unexpected or missing keys.
Evaluating checkpoint_19.pth

*
checkpoint_19.pth metrics:
RMSE=0.5036
MAE=0.0755
Delta1=0.8176
Delta2=0.9663
Delta3=0.9925
REL=0.1387
Lg10=0.0590
t_GPU=0.0298

2024-06-27 19:39:28 - [34m[1mLOGS[0m - model_name:MobileNetV2Edge
class name: <class 'nets.modules.tf_block_topformer.CrossModalBasicLayerV3M4'>
drop_path:[0.0, 0.03333333507180214, 0.06666666269302368, 0.10000000149011612]
self.alpha_list[0]:Parameter containing:
tensor([0.5000], requires_grad=True)
self.alpha_list[1]:Parameter containing:
tensor([0.5000], requires_grad=True)
self.alpha_list[2]:Parameter containing:
tensor([0.5000], requires_grad=True)
len(self.transformer_blocks):12
2024-06-27 19:39:29 - [34m[1mLOGS[0m - best_model_path:./checkpoints/MobileNetV2-TP_ENV4_TMV3M4_LearnableAlpha_OHV4_240627_2/checkpoint_18.pth
2024-06-27 19:39:29 - [34m[1mLOGS[0m - The best model weights loaded w/o unexpected or missing keys.
Evaluating checkpoint_18.pth

*
checkpoint_18.pth metrics:
RMSE=0.5082
MAE=0.0758
Delta1=0.8163
Delta2=0.9662
Delta3=0.9924
REL=0.1381
Lg10=0.0592
t_GPU=0.0303

2024-06-27 19:40:08 - [34m[1mLOGS[0m - model_name:MobileNetV2Edge
class name: <class 'nets.modules.tf_block_topformer.CrossModalBasicLayerV3M4'>
drop_path:[0.0, 0.03333333507180214, 0.06666666269302368, 0.10000000149011612]
self.alpha_list[0]:Parameter containing:
tensor([0.5000], requires_grad=True)
self.alpha_list[1]:Parameter containing:
tensor([0.5000], requires_grad=True)
self.alpha_list[2]:Parameter containing:
tensor([0.5000], requires_grad=True)
len(self.transformer_blocks):12
2024-06-27 19:40:08 - [34m[1mLOGS[0m - best_model_path:./checkpoints/MobileNetV2-TP_ENV4_TMV3M4_LearnableAlpha_OHV4_240627_2/checkpoint_17.pth
2024-06-27 19:40:09 - [34m[1mLOGS[0m - The best model weights loaded w/o unexpected or missing keys.
Evaluating checkpoint_17.pth

*
checkpoint_17.pth metrics:
RMSE=0.5079
MAE=0.0758
Delta1=0.8156
Delta2=0.9662
Delta3=0.9925
REL=0.1377
Lg10=0.0593
t_GPU=0.0295

2024-06-27 19:40:48 - [34m[1mLOGS[0m - model_name:MobileNetV2Edge
class name: <class 'nets.modules.tf_block_topformer.CrossModalBasicLayerV3M4'>
drop_path:[0.0, 0.03333333507180214, 0.06666666269302368, 0.10000000149011612]
self.alpha_list[0]:Parameter containing:
tensor([0.5000], requires_grad=True)
self.alpha_list[1]:Parameter containing:
tensor([0.5000], requires_grad=True)
self.alpha_list[2]:Parameter containing:
tensor([0.5000], requires_grad=True)
len(self.transformer_blocks):12
2024-06-27 19:40:48 - [34m[1mLOGS[0m - best_model_path:./checkpoints/MobileNetV2-TP_ENV4_TMV3M4_LearnableAlpha_OHV4_240627_2/checkpoint_15.pth
2024-06-27 19:40:48 - [34m[1mLOGS[0m - The best model weights loaded w/o unexpected or missing keys.
Evaluating checkpoint_15.pth

*
checkpoint_15.pth metrics:
RMSE=0.5090
MAE=0.0758
Delta1=0.8158
Delta2=0.9663
Delta3=0.9924
REL=0.1374
Lg10=0.0593
t_GPU=0.0302

k:checkpoint_19.pth v:[0.81758484 0.96632232 0.99251137 0.50361251 0.13866326 0.05897585]
k:checkpoint_18.pth v:[0.81627649 0.96617435 0.99243012 0.50819008 0.13812015 0.05923439]
k:checkpoint_17.pth v:[0.81555056 0.96622736 0.99248424 0.50794005 0.13774296 0.05930547]
k:checkpoint_15.pth v:[0.8158126  0.9663445  0.99242058 0.50898661 0.13736548 0.05931462]
